"""æ•°æ®è¿ç§»å·¥å…· - ä» JSON è¿ç§»åˆ° SQLite"""

import os
import sys
import json
import shutil
from datetime import datetime
from typing import Tuple

from .database import get_database
from .logger import get_logger

logger = get_logger('migration')


class DataMigration:
    """æ•°æ®è¿ç§»ç®¡ç†å™¨"""
    
    def __init__(self):
        if getattr(sys, 'frozen', False):
            self.base_dir = os.path.dirname(sys.executable)
        else:
            self.base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        
        self.db = get_database()
        self.history_dir = os.path.join(self.base_dir, 'history')
        self.backup_dir = os.path.join(self.base_dir, 'backup_json')
    
    def check_migration_needed(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦éœ€è¦è¿ç§»"""
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ—§çš„ JSON æ–‡ä»¶
        if not os.path.exists(self.history_dir):
            return False
        
        json_files = [f for f in os.listdir(self.history_dir) if f.endswith('.json')]
        return len(json_files) > 0
    
    def migrate_all(self) -> Tuple[bool, str]:
        """æ‰§è¡Œå®Œæ•´è¿ç§»"""
        try:
            logger.info("å¼€å§‹æ•°æ®è¿ç§»...")
            
            # 1. è¿ç§»å¯¹è¯å†å²
            conv_count, msg_count = self.migrate_conversations()
            logger.info(f"è¿ç§»å¯¹è¯: {conv_count} ä¸ªï¼Œæ¶ˆæ¯: {msg_count} æ¡")
            
            # 2. è¿ç§»ä¸‹è½½è®°å½•
            record_count = self.migrate_download_records()
            logger.info(f"è¿ç§»ä¸‹è½½è®°å½•: {record_count} æ¡")
            
            # 3. è¿ç§»äººæ ¼é…ç½®
            persona_count = self.migrate_personas()
            logger.info(f"è¿ç§»äººæ ¼é…ç½®: {persona_count} ä¸ª")
            
            # 4. å¤‡ä»½åŸå§‹ JSON æ–‡ä»¶
            self.backup_json_files()
            
            summary = (
                f"è¿ç§»å®Œæˆï¼\n"
                f"â€¢ å¯¹è¯: {conv_count} ä¸ª\n"
                f"â€¢ æ¶ˆæ¯: {msg_count} æ¡\n"
                f"â€¢ ä¸‹è½½è®°å½•: {record_count} æ¡\n"
                f"â€¢ äººæ ¼é…ç½®: {persona_count} ä¸ª\n"
                f"åŸå§‹æ–‡ä»¶å·²å¤‡ä»½åˆ°: {self.backup_dir}"
            )
            
            logger.info(summary)
            return True, summary
        
        except Exception as e:
            error_msg = f"è¿ç§»å¤±è´¥: {e}"
            logger.error(error_msg)
            return False, error_msg
    
    def migrate_conversations(self) -> Tuple[int, int]:
        """è¿ç§»å¯¹è¯å†å²"""
        if not os.path.exists(self.history_dir):
            return 0, 0
        
        conv_count = 0
        msg_count = 0
        
        for filename in os.listdir(self.history_dir):
            if not filename.endswith('.json'):
                continue
            
            filepath = os.path.join(self.history_dir, filename)
            
            try:
                with open(filepath, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # æå–å¯¹è¯ä¿¡æ¯
                conv_id = data.get('id', filename.replace('.json', ''))
                title = data.get('title', 'æœªå‘½åå¯¹è¯')
                persona = data.get('persona', 'default')
                created_at = data.get('created_at', data.get('timestamp', datetime.now().isoformat()))
                updated_at = data.get('updated_at', created_at)
                
                # åˆ›å»ºå¯¹è¯
                self.db.create_conversation(conv_id, title, persona)
                
                # æ›´æ–°æ—¶é—´ï¼ˆå› ä¸º create ä¼šè®¾ç½®å½“å‰æ—¶é—´ï¼‰
                conn = self.db.get_connection()
                cursor = conn.cursor()
                cursor.execute('''
                    UPDATE conversations 
                    SET created_at = ?, updated_at = ?
                    WHERE id = ?
                ''', (created_at, updated_at, conv_id))
                conn.commit()
                
                conv_count += 1
                
                # è¿ç§»æ¶ˆæ¯
                if 'sessions' in data:
                    # æ–°æ ¼å¼ï¼ˆå¤šæ¨¡å‹ä¼šè¯ï¼‰
                    for session in data['sessions']:
                        model = session.get('model', 'unknown')
                        for msg in session.get('messages', []):
                            self.db.add_message(
                                conv_id=conv_id,
                                model=model,
                                role=msg.get('role', 'user'),
                                content=msg.get('content', ''),
                                timestamp=msg.get('timestamp', ''),
                                completed_at=msg.get('completed_at')
                            )
                            msg_count += 1
                
                elif 'messages' in data:
                    # æ—§æ ¼å¼ï¼ˆå•æ¨¡å‹ï¼‰
                    model = data.get('model', 'unknown')
                    for msg in data['messages']:
                        self.db.add_message(
                            conv_id=conv_id,
                            model=model,
                            role=msg.get('role', 'user'),
                            content=msg.get('content', ''),
                            timestamp=data.get('timestamp', ''),
                            completed_at=None
                        )
                        msg_count += 1
                
                logger.info(f"è¿ç§»å¯¹è¯: {filename}")
            
            except Exception as e:
                logger.error(f"è¿ç§»å¯¹è¯å¤±è´¥ {filename}: {e}")
                continue
        
        return conv_count, msg_count
    
    def migrate_download_records(self) -> int:
        """è¿ç§»ä¸‹è½½è®°å½•"""
        records_file = os.path.join(self.base_dir, 'download_records.json')
        
        if not os.path.exists(records_file):
            return 0
        
        try:
            with open(records_file, 'r', encoding='utf-8') as f:
                records = json.load(f)
            
            count = 0
            for record_key, record in records.items():
                self.db.add_download_record(
                    record_key=record.get('record_key', record_key),
                    model_name=record.get('model_name', ''),
                    ollama_name=record.get('ollama_name', ''),
                    gguf_path=record.get('gguf_path', ''),
                    quantization=record.get('quantization', ''),
                    model_id=record.get('model_id', '')
                )
                count += 1
            
            logger.info(f"è¿ç§»ä¸‹è½½è®°å½•: {count} æ¡")
            return count
        
        except Exception as e:
            logger.error(f"è¿ç§»ä¸‹è½½è®°å½•å¤±è´¥: {e}")
            return 0
    
    def migrate_personas(self) -> int:
        """è¿ç§»äººæ ¼é…ç½®"""
        personas_file = os.path.join(self.base_dir, 'personas.json')
        
        if not os.path.exists(personas_file):
            # æ·»åŠ é»˜è®¤äººæ ¼
            self.db.add_persona(
                key='default',
                name='é»˜è®¤åŠ©æ‰‹',
                icon='ğŸ¤–',
                description='é€šç”¨AIåŠ©æ‰‹',
                system_prompt=''
            )
            return 1
        
        try:
            with open(personas_file, 'r', encoding='utf-8') as f:
                personas = json.load(f)
            
            count = 0
            for key, persona in personas.items():
                self.db.add_persona(
                    key=key,
                    name=persona.get('name', 'æœªå‘½å'),
                    icon=persona.get('icon', 'ğŸ¤–'),
                    icon_path=persona.get('icon_path', ''),
                    description=persona.get('description', ''),
                    system_prompt=persona.get('system_prompt', '')
                )
                count += 1
            
            logger.info(f"è¿ç§»äººæ ¼é…ç½®: {count} ä¸ª")
            return count
        
        except Exception as e:
            logger.error(f"è¿ç§»äººæ ¼é…ç½®å¤±è´¥: {e}")
            return 0
    
    def backup_json_files(self):
        """å¤‡ä»½åŸå§‹ JSON æ–‡ä»¶"""
        try:
            # åˆ›å»ºå¤‡ä»½ç›®å½•
            os.makedirs(self.backup_dir, exist_ok=True)
            
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            backup_subdir = os.path.join(self.backup_dir, f'backup_{timestamp}')
            os.makedirs(backup_subdir, exist_ok=True)
            
            # å¤‡ä»½å¯¹è¯å†å²
            if os.path.exists(self.history_dir):
                history_backup = os.path.join(backup_subdir, 'history')
                shutil.copytree(self.history_dir, history_backup)
                logger.info(f"å¤‡ä»½å¯¹è¯å†å²åˆ°: {history_backup}")
            
            # å¤‡ä»½ä¸‹è½½è®°å½•
            records_file = os.path.join(self.base_dir, 'download_records.json')
            if os.path.exists(records_file):
                shutil.copy(records_file, os.path.join(backup_subdir, 'download_records.json'))
                logger.info("å¤‡ä»½ä¸‹è½½è®°å½•")
            
            # å¤‡ä»½äººæ ¼é…ç½®
            personas_file = os.path.join(self.base_dir, 'personas.json')
            if os.path.exists(personas_file):
                shutil.copy(personas_file, os.path.join(backup_subdir, 'personas.json'))
                logger.info("å¤‡ä»½äººæ ¼é…ç½®")
            
            logger.info(f"æ‰€æœ‰æ–‡ä»¶å·²å¤‡ä»½åˆ°: {backup_subdir}")
        
        except Exception as e:
            logger.error(f"å¤‡ä»½æ–‡ä»¶å¤±è´¥: {e}")
    
    def rollback(self, backup_timestamp: str = None):
        """å›æ»šåˆ° JSON æ ¼å¼ï¼ˆä»å¤‡ä»½æ¢å¤ï¼‰"""
        try:
            if backup_timestamp:
                backup_path = os.path.join(self.backup_dir, f'backup_{backup_timestamp}')
            else:
                # ä½¿ç”¨æœ€æ–°çš„å¤‡ä»½
                backups = sorted([d for d in os.listdir(self.backup_dir) if d.startswith('backup_')])
                if not backups:
                    return False, "æ²¡æœ‰æ‰¾åˆ°å¤‡ä»½"
                backup_path = os.path.join(self.backup_dir, backups[-1])
            
            if not os.path.exists(backup_path):
                return False, f"å¤‡ä»½ä¸å­˜åœ¨: {backup_path}"
            
            # æ¢å¤å¯¹è¯å†å²
            history_backup = os.path.join(backup_path, 'history')
            if os.path.exists(history_backup):
                if os.path.exists(self.history_dir):
                    shutil.rmtree(self.history_dir)
                shutil.copytree(history_backup, self.history_dir)
            
            # æ¢å¤ä¸‹è½½è®°å½•
            records_backup = os.path.join(backup_path, 'download_records.json')
            if os.path.exists(records_backup):
                shutil.copy(records_backup, os.path.join(self.base_dir, 'download_records.json'))
            
            # æ¢å¤äººæ ¼é…ç½®
            personas_backup = os.path.join(backup_path, 'personas.json')
            if os.path.exists(personas_backup):
                shutil.copy(personas_backup, os.path.join(self.base_dir, 'personas.json'))
            
            logger.info(f"å·²ä»å¤‡ä»½æ¢å¤: {backup_path}")
            return True, f"å·²æ¢å¤åˆ°: {backup_path}"
        
        except Exception as e:
            error_msg = f"å›æ»šå¤±è´¥: {e}"
            logger.error(error_msg)
            return False, error_msg


def auto_migrate_on_startup():
    """å¯åŠ¨æ—¶è‡ªåŠ¨æ£€æŸ¥å¹¶è¿ç§»"""
    migration = DataMigration()
    
    if migration.check_migration_needed():
        logger.info("æ£€æµ‹åˆ°æ—§çš„ JSON æ•°æ®ï¼Œå¼€å§‹è‡ªåŠ¨è¿ç§»...")
        success, message = migration.migrate_all()
        
        if success:
            logger.info("è‡ªåŠ¨è¿ç§»æˆåŠŸ")
        else:
            logger.error(f"è‡ªåŠ¨è¿ç§»å¤±è´¥: {message}")
        
        return success, message
    else:
        logger.info("æ— éœ€è¿ç§»")
        return True, "æ— éœ€è¿ç§»"
